{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2118595,"sourceType":"datasetVersion","datasetId":1271215}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-31T04:57:08.242010Z","iopub.execute_input":"2025-03-31T04:57:08.242280Z","iopub.status.idle":"2025-03-31T04:57:08.245455Z","shell.execute_reply.started":"2025-03-31T04:57:08.242257Z","shell.execute_reply":"2025-03-31T04:57:08.244667Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!git clone https://github.com/ultralytics/yolov5.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:34:41.496020Z","iopub.execute_input":"2025-03-31T14:34:41.496264Z","iopub.status.idle":"2025-03-31T14:34:43.407852Z","shell.execute_reply.started":"2025-03-31T14:34:41.496242Z","shell.execute_reply":"2025-03-31T14:34:43.406746Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'yolov5'...\nremote: Enumerating objects: 17360, done.\u001b[K\nremote: Counting objects: 100% (52/52), done.\u001b[K\nremote: Compressing objects: 100% (34/34), done.\u001b[K\nremote: Total 17360 (delta 36), reused 18 (delta 18), pack-reused 17308 (from 2)\u001b[K\nReceiving objects: 100% (17360/17360), 16.23 MiB | 27.39 MiB/s, done.\nResolving deltas: 100% (11898/11898), done.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nos.chdir('yolov5')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:34:46.466558Z","iopub.execute_input":"2025-03-31T14:34:46.466887Z","iopub.status.idle":"2025-03-31T14:34:46.470630Z","shell.execute_reply.started":"2025-03-31T14:34:46.466856Z","shell.execute_reply":"2025-03-31T14:34:46.469770Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"ls","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:34:50.682519Z","iopub.execute_input":"2025-03-31T14:34:50.682796Z","iopub.status.idle":"2025-03-31T14:34:50.803356Z","shell.execute_reply.started":"2025-03-31T14:34:50.682774Z","shell.execute_reply":"2025-03-31T14:34:50.802383Z"}},"outputs":[{"name":"stdout","text":"benchmarks.py    \u001b[0m\u001b[01;34mdata\u001b[0m/       LICENSE         README.zh-CN.md   tutorial.ipynb\nCITATION.cff     detect.py   \u001b[01;34mmodels\u001b[0m/         requirements.txt  \u001b[01;34mutils\u001b[0m/\n\u001b[01;34mclassify\u001b[0m/        export.py   pyproject.toml  \u001b[01;34msegment\u001b[0m/          val.py\nCONTRIBUTING.md  hubconf.py  README.md       train.py\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"os.mkdir('data_images')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:34:53.204774Z","iopub.execute_input":"2025-03-31T14:34:53.205135Z","iopub.status.idle":"2025-03-31T14:34:53.209291Z","shell.execute_reply.started":"2025-03-31T14:34:53.205098Z","shell.execute_reply":"2025-03-31T14:34:53.208515Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"train= 'data_images/train'\ntest = 'data_images/test'\nos.mkdir(train)\nos.mkdir(test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:34:55.803339Z","iopub.execute_input":"2025-03-31T14:34:55.803635Z","iopub.status.idle":"2025-03-31T14:34:55.808531Z","shell.execute_reply.started":"2025-03-31T14:34:55.803612Z","shell.execute_reply":"2025-03-31T14:34:55.807395Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"ls","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:34:58.299736Z","iopub.execute_input":"2025-03-31T14:34:58.300039Z","iopub.status.idle":"2025-03-31T14:34:58.417169Z","shell.execute_reply.started":"2025-03-31T14:34:58.300011Z","shell.execute_reply":"2025-03-31T14:34:58.416338Z"}},"outputs":[{"name":"stdout","text":"benchmarks.py    \u001b[0m\u001b[01;34mdata\u001b[0m/         hubconf.py      README.md         train.py\nCITATION.cff     \u001b[01;34mdata_images\u001b[0m/  LICENSE         README.zh-CN.md   tutorial.ipynb\n\u001b[01;34mclassify\u001b[0m/        detect.py     \u001b[01;34mmodels\u001b[0m/         requirements.txt  \u001b[01;34mutils\u001b[0m/\nCONTRIBUTING.md  export.py     pyproject.toml  \u001b[01;34msegment\u001b[0m/          val.py\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"os.chdir('/kaggle/input')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:35:00.580730Z","iopub.execute_input":"2025-03-31T14:35:00.581020Z","iopub.status.idle":"2025-03-31T14:35:00.585209Z","shell.execute_reply.started":"2025-03-31T14:35:00.580997Z","shell.execute_reply":"2025-03-31T14:35:00.584322Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import os\nfrom glob import glob\nimport pandas as pd\nfrom functools import reduce\nfrom xml.etree import ElementTree as et","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:35:02.421965Z","iopub.execute_input":"2025-03-31T14:35:02.422309Z","iopub.status.idle":"2025-03-31T14:35:02.744819Z","shell.execute_reply.started":"2025-03-31T14:35:02.422279Z","shell.execute_reply":"2025-03-31T14:35:02.744147Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"xml_list=glob(\"/kaggle/input/pascal-voc-2012-dataset/VOC2012_train_val/VOC2012_train_val/Annotations/*.xml\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:35:05.408185Z","iopub.execute_input":"2025-03-31T14:35:05.408593Z","iopub.status.idle":"2025-03-31T14:35:05.748799Z","shell.execute_reply.started":"2025-03-31T14:35:05.408569Z","shell.execute_reply":"2025-03-31T14:35:05.748113Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"#xml_list","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T04:57:08.631625Z","iopub.status.idle":"2025-03-31T04:57:08.631940Z","shell.execute_reply":"2025-03-31T04:57:08.631827Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#read xml files\n# extract filename,size(width,height),object(name,xmin,xmax,ymin,ymax)\ndef extract_text(filename):\n    tree=et.parse(filename)\n    root=tree.getroot()\n    \n    #extract file name\n    image_name=root.find('filename').text\n    \n    #width and height of the image\n    width=root.find('size').find('width').text\n    height=root.find('size').find('height').text\n    \n    objs =root.findall('object')\n    parser =[]\n    for obj in objs:\n        name=obj.find('name').text\n        bndbox=obj.find('bndbox')\n        xmin=bndbox.find('xmin').text\n        xmax=bndbox.find('xmax').text\n        ymin=bndbox.find('ymin').text\n        ymax=bndbox.find('ymax').text\n        parser.extend([image_name,width,height,name,xmin,xmax,ymin,ymax])\n    return parser","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:35:07.897842Z","iopub.execute_input":"2025-03-31T14:35:07.898152Z","iopub.status.idle":"2025-03-31T14:35:07.904129Z","shell.execute_reply.started":"2025-03-31T14:35:07.898128Z","shell.execute_reply":"2025-03-31T14:35:07.903156Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"parser_all=list(map(extract_text,xml_list))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:35:11.394691Z","iopub.execute_input":"2025-03-31T14:35:11.395014Z","iopub.status.idle":"2025-03-31T14:37:25.899430Z","shell.execute_reply.started":"2025-03-31T14:35:11.394985Z","shell.execute_reply":"2025-03-31T14:37:25.898697Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"data_train = reduce(lambda x,y : x+y,parser_all)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:38:00.854623Z","iopub.execute_input":"2025-03-31T14:38:00.854924Z","iopub.status.idle":"2025-03-31T14:38:21.913329Z","shell.execute_reply.started":"2025-03-31T14:38:00.854903Z","shell.execute_reply":"2025-03-31T14:38:21.912383Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"dataList = []\ni=0\nwhile(i<len(data_train)):\n    dataList.append(data_train[i:i+8])\n    i+=8","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:38:43.528126Z","iopub.execute_input":"2025-03-31T14:38:43.528430Z","iopub.status.idle":"2025-03-31T14:38:43.634595Z","shell.execute_reply.started":"2025-03-31T14:38:43.528405Z","shell.execute_reply":"2025-03-31T14:38:43.633741Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"#dataList","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T04:57:08.637709Z","iopub.status.idle":"2025-03-31T04:57:08.638087Z","shell.execute_reply":"2025-03-31T04:57:08.637910Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.DataFrame(dataList,columns=['filename','width','height','name','xmin','xmax','ymin','ymax'])\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:38:47.951362Z","iopub.execute_input":"2025-03-31T14:38:47.951694Z","iopub.status.idle":"2025-03-31T14:38:48.002218Z","shell.execute_reply.started":"2025-03-31T14:38:47.951664Z","shell.execute_reply":"2025-03-31T14:38:48.001256Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"          filename width height       name xmin xmax ymin ymax\n0  2011_006424.jpg   333    500     person   67  269   56  369\n1  2010_003717.jpg   500    375       sofa   34  498    1  242\n2  2010_003717.jpg   500    375     bottle  432  500  305  332\n3  2009_000488.jpg   500    375  tvmonitor   21  193    1   95\n4  2009_000488.jpg   500    375        cat  224  287  159  229","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>width</th>\n      <th>height</th>\n      <th>name</th>\n      <th>xmin</th>\n      <th>xmax</th>\n      <th>ymin</th>\n      <th>ymax</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2011_006424.jpg</td>\n      <td>333</td>\n      <td>500</td>\n      <td>person</td>\n      <td>67</td>\n      <td>269</td>\n      <td>56</td>\n      <td>369</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2010_003717.jpg</td>\n      <td>500</td>\n      <td>375</td>\n      <td>sofa</td>\n      <td>34</td>\n      <td>498</td>\n      <td>1</td>\n      <td>242</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2010_003717.jpg</td>\n      <td>500</td>\n      <td>375</td>\n      <td>bottle</td>\n      <td>432</td>\n      <td>500</td>\n      <td>305</td>\n      <td>332</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2009_000488.jpg</td>\n      <td>500</td>\n      <td>375</td>\n      <td>tvmonitor</td>\n      <td>21</td>\n      <td>193</td>\n      <td>1</td>\n      <td>95</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2009_000488.jpg</td>\n      <td>500</td>\n      <td>375</td>\n      <td>cat</td>\n      <td>224</td>\n      <td>287</td>\n      <td>159</td>\n      <td>229</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"# Convert numeric columns safely (round float values before conversion)\nnumeric_columns = ['width', 'height', 'xmin', 'xmax', 'ymin', 'ymax']\ndf[numeric_columns] = df[numeric_columns].apply(pd.to_numeric, errors='coerce').round().astype('int')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:38:51.077976Z","iopub.execute_input":"2025-03-31T14:38:51.078281Z","iopub.status.idle":"2025-03-31T14:38:51.235290Z","shell.execute_reply.started":"2025-03-31T14:38:51.078259Z","shell.execute_reply":"2025-03-31T14:38:51.234558Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:38:53.816677Z","iopub.execute_input":"2025-03-31T14:38:53.817066Z","iopub.status.idle":"2025-03-31T14:38:53.849179Z","shell.execute_reply.started":"2025-03-31T14:38:53.817030Z","shell.execute_reply":"2025-03-31T14:38:53.848245Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 40138 entries, 0 to 40137\nData columns (total 8 columns):\n #   Column    Non-Null Count  Dtype \n---  ------    --------------  ----- \n 0   filename  40138 non-null  object\n 1   width     40138 non-null  int64 \n 2   height    40138 non-null  int64 \n 3   name      40138 non-null  object\n 4   xmin      40138 non-null  int64 \n 5   xmax      40138 non-null  int64 \n 6   ymin      40138 non-null  int64 \n 7   ymax      40138 non-null  int64 \ndtypes: int64(6), object(2)\nmemory usage: 2.4+ MB\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"#center x,center y\ndf['center_x']=((df['xmax']+df['xmin'])/2)/df['width']\ndf['center_y']=((df['ymax']+df['ymin'])/2)/df['height']\ndf['w']=(df['xmax']-df['xmin'])/df['width']\ndf['h']=(df['ymax']-df['ymin'])/df['height']\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:38:56.629718Z","iopub.execute_input":"2025-03-31T14:38:56.630034Z","iopub.status.idle":"2025-03-31T14:38:56.647734Z","shell.execute_reply.started":"2025-03-31T14:38:56.630005Z","shell.execute_reply":"2025-03-31T14:38:56.647140Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:38:59.082316Z","iopub.execute_input":"2025-03-31T14:38:59.082603Z","iopub.status.idle":"2025-03-31T14:38:59.094674Z","shell.execute_reply.started":"2025-03-31T14:38:59.082580Z","shell.execute_reply":"2025-03-31T14:38:59.093878Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"          filename  width  height       name  xmin  xmax  ymin  ymax  \\\n0  2011_006424.jpg    333     500     person    67   269    56   369   \n1  2010_003717.jpg    500     375       sofa    34   498     1   242   \n2  2010_003717.jpg    500     375     bottle   432   500   305   332   \n3  2009_000488.jpg    500     375  tvmonitor    21   193     1    95   \n4  2009_000488.jpg    500     375        cat   224   287   159   229   \n\n   center_x  center_y         w         h  \n0  0.504505  0.425000  0.606607  0.626000  \n1  0.532000  0.324000  0.928000  0.642667  \n2  0.932000  0.849333  0.136000  0.072000  \n3  0.214000  0.128000  0.344000  0.250667  \n4  0.511000  0.517333  0.126000  0.186667  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>width</th>\n      <th>height</th>\n      <th>name</th>\n      <th>xmin</th>\n      <th>xmax</th>\n      <th>ymin</th>\n      <th>ymax</th>\n      <th>center_x</th>\n      <th>center_y</th>\n      <th>w</th>\n      <th>h</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2011_006424.jpg</td>\n      <td>333</td>\n      <td>500</td>\n      <td>person</td>\n      <td>67</td>\n      <td>269</td>\n      <td>56</td>\n      <td>369</td>\n      <td>0.504505</td>\n      <td>0.425000</td>\n      <td>0.606607</td>\n      <td>0.626000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2010_003717.jpg</td>\n      <td>500</td>\n      <td>375</td>\n      <td>sofa</td>\n      <td>34</td>\n      <td>498</td>\n      <td>1</td>\n      <td>242</td>\n      <td>0.532000</td>\n      <td>0.324000</td>\n      <td>0.928000</td>\n      <td>0.642667</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2010_003717.jpg</td>\n      <td>500</td>\n      <td>375</td>\n      <td>bottle</td>\n      <td>432</td>\n      <td>500</td>\n      <td>305</td>\n      <td>332</td>\n      <td>0.932000</td>\n      <td>0.849333</td>\n      <td>0.136000</td>\n      <td>0.072000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2009_000488.jpg</td>\n      <td>500</td>\n      <td>375</td>\n      <td>tvmonitor</td>\n      <td>21</td>\n      <td>193</td>\n      <td>1</td>\n      <td>95</td>\n      <td>0.214000</td>\n      <td>0.128000</td>\n      <td>0.344000</td>\n      <td>0.250667</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2009_000488.jpg</td>\n      <td>500</td>\n      <td>375</td>\n      <td>cat</td>\n      <td>224</td>\n      <td>287</td>\n      <td>159</td>\n      <td>229</td>\n      <td>0.511000</td>\n      <td>0.517333</td>\n      <td>0.126000</td>\n      <td>0.186667</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"images=df['filename'].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:39:01.408006Z","iopub.execute_input":"2025-03-31T14:39:01.408341Z","iopub.status.idle":"2025-03-31T14:39:01.417446Z","shell.execute_reply.started":"2025-03-31T14:39:01.408316Z","shell.execute_reply":"2025-03-31T14:39:01.416593Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"len(images)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:39:03.203540Z","iopub.execute_input":"2025-03-31T14:39:03.203813Z","iopub.status.idle":"2025-03-31T14:39:03.208841Z","shell.execute_reply.started":"2025-03-31T14:39:03.203792Z","shell.execute_reply":"2025-03-31T14:39:03.207889Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"17125"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":" #test data set\nxml_test=glob(\"/kaggle/input/pascal-voc-2012-dataset/VOC2012_test/VOC2012_test/Annotations/*.xml\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:39:05.184536Z","iopub.execute_input":"2025-03-31T14:39:05.184846Z","iopub.status.idle":"2025-03-31T14:39:05.293376Z","shell.execute_reply.started":"2025-03-31T14:39:05.184819Z","shell.execute_reply":"2025-03-31T14:39:05.292497Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"parser_all_test=list(map(extract_text,xml_test))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:39:07.877308Z","iopub.execute_input":"2025-03-31T14:39:07.877594Z","iopub.status.idle":"2025-03-31T14:39:48.512539Z","shell.execute_reply.started":"2025-03-31T14:39:07.877572Z","shell.execute_reply":"2025-03-31T14:39:48.511830Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"data_test = reduce(lambda x,y : x+y,parser_all_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:40:01.801611Z","iopub.execute_input":"2025-03-31T14:40:01.801911Z","iopub.status.idle":"2025-03-31T14:40:02.501835Z","shell.execute_reply.started":"2025-03-31T14:40:01.801889Z","shell.execute_reply":"2025-03-31T14:40:02.501149Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"dataListTest = []\ni=0\nwhile(i<len(data_test)):\n    dataListTest.append(data_test[i:i+8])\n    i+=8","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:40:08.152529Z","iopub.execute_input":"2025-03-31T14:40:08.152819Z","iopub.status.idle":"2025-03-31T14:40:08.164465Z","shell.execute_reply.started":"2025-03-31T14:40:08.152797Z","shell.execute_reply":"2025-03-31T14:40:08.163529Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# dataListTest\ndf_test = pd.DataFrame(dataListTest,columns=['filename','width','height','name','xmin','xmax','ymin','ymax'])\ndf_test.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:40:10.993289Z","iopub.execute_input":"2025-03-31T14:40:10.993622Z","iopub.status.idle":"2025-03-31T14:40:11.008428Z","shell.execute_reply.started":"2025-03-31T14:40:10.993595Z","shell.execute_reply":"2025-03-31T14:40:11.007611Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"          filename width height    name xmin xmax ymin ymax\n0  2010_006298.jpg   500    375  person  244  285  135  200\n1  2010_006298.jpg   500    375  person  251  319  139  247\n2  2012_003858.jpg   336    448  person   29  161  176  448\n3  2012_003788.jpg   500    394  person  257  458   11  331\n4  2011_006625.jpg   375    500  person  115  320    1  367","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>width</th>\n      <th>height</th>\n      <th>name</th>\n      <th>xmin</th>\n      <th>xmax</th>\n      <th>ymin</th>\n      <th>ymax</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2010_006298.jpg</td>\n      <td>500</td>\n      <td>375</td>\n      <td>person</td>\n      <td>244</td>\n      <td>285</td>\n      <td>135</td>\n      <td>200</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2010_006298.jpg</td>\n      <td>500</td>\n      <td>375</td>\n      <td>person</td>\n      <td>251</td>\n      <td>319</td>\n      <td>139</td>\n      <td>247</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2012_003858.jpg</td>\n      <td>336</td>\n      <td>448</td>\n      <td>person</td>\n      <td>29</td>\n      <td>161</td>\n      <td>176</td>\n      <td>448</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2012_003788.jpg</td>\n      <td>500</td>\n      <td>394</td>\n      <td>person</td>\n      <td>257</td>\n      <td>458</td>\n      <td>11</td>\n      <td>331</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2011_006625.jpg</td>\n      <td>375</td>\n      <td>500</td>\n      <td>person</td>\n      <td>115</td>\n      <td>320</td>\n      <td>1</td>\n      <td>367</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"# Convert numeric columns safely (round float values before conversion)\nnumeric_columns = ['width', 'height', 'xmin', 'xmax', 'ymin', 'ymax']\ndf_test[numeric_columns] = df_test[numeric_columns].apply(pd.to_numeric, errors='coerce').round().astype('int')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:40:13.482759Z","iopub.execute_input":"2025-03-31T14:40:13.483040Z","iopub.status.idle":"2025-03-31T14:40:13.515139Z","shell.execute_reply.started":"2025-03-31T14:40:13.483019Z","shell.execute_reply":"2025-03-31T14:40:13.514299Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"df_test.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:40:15.376738Z","iopub.execute_input":"2025-03-31T14:40:15.377142Z","iopub.status.idle":"2025-03-31T14:40:15.389463Z","shell.execute_reply.started":"2025-03-31T14:40:15.377109Z","shell.execute_reply":"2025-03-31T14:40:15.388369Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 7330 entries, 0 to 7329\nData columns (total 8 columns):\n #   Column    Non-Null Count  Dtype \n---  ------    --------------  ----- \n 0   filename  7330 non-null   object\n 1   width     7330 non-null   int64 \n 2   height    7330 non-null   int64 \n 3   name      7330 non-null   object\n 4   xmin      7330 non-null   int64 \n 5   xmax      7330 non-null   int64 \n 6   ymin      7330 non-null   int64 \n 7   ymax      7330 non-null   int64 \ndtypes: int64(6), object(2)\nmemory usage: 458.2+ KB\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"#center x,center y\ndf_test['center_x']=((df_test['xmax']+df_test['xmin'])/2)/df_test['width']\ndf_test['center_y']=((df_test['ymax']+df_test['ymin'])/2)/df_test['height']\ndf_test['w']=(df_test['xmax']-df_test['xmin'])/df_test['width']\ndf_test['h']=(df_test['ymax']-df_test['ymin'])/df_test['height']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:40:17.969353Z","iopub.execute_input":"2025-03-31T14:40:17.969660Z","iopub.status.idle":"2025-03-31T14:40:17.978361Z","shell.execute_reply.started":"2025-03-31T14:40:17.969633Z","shell.execute_reply":"2025-03-31T14:40:17.977478Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"df_test.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:40:20.640548Z","iopub.execute_input":"2025-03-31T14:40:20.640866Z","iopub.status.idle":"2025-03-31T14:40:20.652533Z","shell.execute_reply.started":"2025-03-31T14:40:20.640840Z","shell.execute_reply":"2025-03-31T14:40:20.651797Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"          filename  width  height    name  xmin  xmax  ymin  ymax  center_x  \\\n0  2010_006298.jpg    500     375  person   244   285   135   200  0.529000   \n1  2010_006298.jpg    500     375  person   251   319   139   247  0.570000   \n2  2012_003858.jpg    336     448  person    29   161   176   448  0.282738   \n3  2012_003788.jpg    500     394  person   257   458    11   331  0.715000   \n4  2011_006625.jpg    375     500  person   115   320     1   367  0.580000   \n\n   center_y         w         h  \n0  0.446667  0.082000  0.173333  \n1  0.514667  0.136000  0.288000  \n2  0.696429  0.392857  0.607143  \n3  0.434010  0.402000  0.812183  \n4  0.368000  0.546667  0.732000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>width</th>\n      <th>height</th>\n      <th>name</th>\n      <th>xmin</th>\n      <th>xmax</th>\n      <th>ymin</th>\n      <th>ymax</th>\n      <th>center_x</th>\n      <th>center_y</th>\n      <th>w</th>\n      <th>h</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2010_006298.jpg</td>\n      <td>500</td>\n      <td>375</td>\n      <td>person</td>\n      <td>244</td>\n      <td>285</td>\n      <td>135</td>\n      <td>200</td>\n      <td>0.529000</td>\n      <td>0.446667</td>\n      <td>0.082000</td>\n      <td>0.173333</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2010_006298.jpg</td>\n      <td>500</td>\n      <td>375</td>\n      <td>person</td>\n      <td>251</td>\n      <td>319</td>\n      <td>139</td>\n      <td>247</td>\n      <td>0.570000</td>\n      <td>0.514667</td>\n      <td>0.136000</td>\n      <td>0.288000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2012_003858.jpg</td>\n      <td>336</td>\n      <td>448</td>\n      <td>person</td>\n      <td>29</td>\n      <td>161</td>\n      <td>176</td>\n      <td>448</td>\n      <td>0.282738</td>\n      <td>0.696429</td>\n      <td>0.392857</td>\n      <td>0.607143</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2012_003788.jpg</td>\n      <td>500</td>\n      <td>394</td>\n      <td>person</td>\n      <td>257</td>\n      <td>458</td>\n      <td>11</td>\n      <td>331</td>\n      <td>0.715000</td>\n      <td>0.434010</td>\n      <td>0.402000</td>\n      <td>0.812183</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2011_006625.jpg</td>\n      <td>375</td>\n      <td>500</td>\n      <td>person</td>\n      <td>115</td>\n      <td>320</td>\n      <td>1</td>\n      <td>367</td>\n      <td>0.580000</td>\n      <td>0.368000</td>\n      <td>0.546667</td>\n      <td>0.732000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"img_train = tuple(df['filename'].unique())\nimg_test = tuple(df_test['filename'].unique())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:40:23.025970Z","iopub.execute_input":"2025-03-31T14:40:23.026297Z","iopub.status.idle":"2025-03-31T14:40:23.037359Z","shell.execute_reply.started":"2025-03-31T14:40:23.026272Z","shell.execute_reply":"2025-03-31T14:40:23.036624Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"len(img_train),len(img_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:40:25.445231Z","iopub.execute_input":"2025-03-31T14:40:25.445535Z","iopub.status.idle":"2025-03-31T14:40:25.450981Z","shell.execute_reply.started":"2025-03-31T14:40:25.445513Z","shell.execute_reply":"2025-03-31T14:40:25.450153Z"}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"(17125, 5138)"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:40:27.378196Z","iopub.execute_input":"2025-03-31T14:40:27.378473Z","iopub.status.idle":"2025-03-31T14:40:27.389904Z","shell.execute_reply.started":"2025-03-31T14:40:27.378453Z","shell.execute_reply":"2025-03-31T14:40:27.389174Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"          filename  width  height       name  xmin  xmax  ymin  ymax  \\\n0  2011_006424.jpg    333     500     person    67   269    56   369   \n1  2010_003717.jpg    500     375       sofa    34   498     1   242   \n2  2010_003717.jpg    500     375     bottle   432   500   305   332   \n3  2009_000488.jpg    500     375  tvmonitor    21   193     1    95   \n4  2009_000488.jpg    500     375        cat   224   287   159   229   \n\n   center_x  center_y         w         h  \n0  0.504505  0.425000  0.606607  0.626000  \n1  0.532000  0.324000  0.928000  0.642667  \n2  0.932000  0.849333  0.136000  0.072000  \n3  0.214000  0.128000  0.344000  0.250667  \n4  0.511000  0.517333  0.126000  0.186667  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>width</th>\n      <th>height</th>\n      <th>name</th>\n      <th>xmin</th>\n      <th>xmax</th>\n      <th>ymin</th>\n      <th>ymax</th>\n      <th>center_x</th>\n      <th>center_y</th>\n      <th>w</th>\n      <th>h</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2011_006424.jpg</td>\n      <td>333</td>\n      <td>500</td>\n      <td>person</td>\n      <td>67</td>\n      <td>269</td>\n      <td>56</td>\n      <td>369</td>\n      <td>0.504505</td>\n      <td>0.425000</td>\n      <td>0.606607</td>\n      <td>0.626000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2010_003717.jpg</td>\n      <td>500</td>\n      <td>375</td>\n      <td>sofa</td>\n      <td>34</td>\n      <td>498</td>\n      <td>1</td>\n      <td>242</td>\n      <td>0.532000</td>\n      <td>0.324000</td>\n      <td>0.928000</td>\n      <td>0.642667</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2010_003717.jpg</td>\n      <td>500</td>\n      <td>375</td>\n      <td>bottle</td>\n      <td>432</td>\n      <td>500</td>\n      <td>305</td>\n      <td>332</td>\n      <td>0.932000</td>\n      <td>0.849333</td>\n      <td>0.136000</td>\n      <td>0.072000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2009_000488.jpg</td>\n      <td>500</td>\n      <td>375</td>\n      <td>tvmonitor</td>\n      <td>21</td>\n      <td>193</td>\n      <td>1</td>\n      <td>95</td>\n      <td>0.214000</td>\n      <td>0.128000</td>\n      <td>0.344000</td>\n      <td>0.250667</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2009_000488.jpg</td>\n      <td>500</td>\n      <td>375</td>\n      <td>cat</td>\n      <td>224</td>\n      <td>287</td>\n      <td>159</td>\n      <td>229</td>\n      <td>0.511000</td>\n      <td>0.517333</td>\n      <td>0.126000</td>\n      <td>0.186667</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"df_test.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:40:29.520860Z","iopub.execute_input":"2025-03-31T14:40:29.521167Z","iopub.status.idle":"2025-03-31T14:40:29.533210Z","shell.execute_reply.started":"2025-03-31T14:40:29.521143Z","shell.execute_reply":"2025-03-31T14:40:29.532376Z"}},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"          filename  width  height    name  xmin  xmax  ymin  ymax  center_x  \\\n0  2010_006298.jpg    500     375  person   244   285   135   200  0.529000   \n1  2010_006298.jpg    500     375  person   251   319   139   247  0.570000   \n2  2012_003858.jpg    336     448  person    29   161   176   448  0.282738   \n3  2012_003788.jpg    500     394  person   257   458    11   331  0.715000   \n4  2011_006625.jpg    375     500  person   115   320     1   367  0.580000   \n\n   center_y         w         h  \n0  0.446667  0.082000  0.173333  \n1  0.514667  0.136000  0.288000  \n2  0.696429  0.392857  0.607143  \n3  0.434010  0.402000  0.812183  \n4  0.368000  0.546667  0.732000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>width</th>\n      <th>height</th>\n      <th>name</th>\n      <th>xmin</th>\n      <th>xmax</th>\n      <th>ymin</th>\n      <th>ymax</th>\n      <th>center_x</th>\n      <th>center_y</th>\n      <th>w</th>\n      <th>h</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2010_006298.jpg</td>\n      <td>500</td>\n      <td>375</td>\n      <td>person</td>\n      <td>244</td>\n      <td>285</td>\n      <td>135</td>\n      <td>200</td>\n      <td>0.529000</td>\n      <td>0.446667</td>\n      <td>0.082000</td>\n      <td>0.173333</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2010_006298.jpg</td>\n      <td>500</td>\n      <td>375</td>\n      <td>person</td>\n      <td>251</td>\n      <td>319</td>\n      <td>139</td>\n      <td>247</td>\n      <td>0.570000</td>\n      <td>0.514667</td>\n      <td>0.136000</td>\n      <td>0.288000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2012_003858.jpg</td>\n      <td>336</td>\n      <td>448</td>\n      <td>person</td>\n      <td>29</td>\n      <td>161</td>\n      <td>176</td>\n      <td>448</td>\n      <td>0.282738</td>\n      <td>0.696429</td>\n      <td>0.392857</td>\n      <td>0.607143</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2012_003788.jpg</td>\n      <td>500</td>\n      <td>394</td>\n      <td>person</td>\n      <td>257</td>\n      <td>458</td>\n      <td>11</td>\n      <td>331</td>\n      <td>0.715000</td>\n      <td>0.434010</td>\n      <td>0.402000</td>\n      <td>0.812183</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2011_006625.jpg</td>\n      <td>375</td>\n      <td>500</td>\n      <td>person</td>\n      <td>115</td>\n      <td>320</td>\n      <td>1</td>\n      <td>367</td>\n      <td>0.580000</td>\n      <td>0.368000</td>\n      <td>0.546667</td>\n      <td>0.732000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"#Label encoding\n# df['name'].value_counts()\ndef label_encoding(x):\n        labels = {'person':0,'car':1,'chair':2,'bottle':3,'pottedplant':4,'bird':5,\n                  'dog':6,'sofa':7,'bicycle':8,'horse':9,'boat':10,'motorbike':11,'cat':12,\n                  'tvmonitor':13,'cow':14,'sheep':15,'aeroplane':16,'train':17,'diningtable':18,\n                  'bus':19}\n        return labels[x]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:40:31.871135Z","iopub.execute_input":"2025-03-31T14:40:31.871476Z","iopub.status.idle":"2025-03-31T14:40:31.875854Z","shell.execute_reply.started":"2025-03-31T14:40:31.871450Z","shell.execute_reply":"2025-03-31T14:40:31.875016Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"df_train=df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:40:33.600865Z","iopub.execute_input":"2025-03-31T14:40:33.601165Z","iopub.status.idle":"2025-03-31T14:40:33.604606Z","shell.execute_reply.started":"2025-03-31T14:40:33.601142Z","shell.execute_reply":"2025-03-31T14:40:33.603712Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"df_train['id']=df_train['name'].apply(label_encoding)\ndf_test['id']=df_test['name'].apply(label_encoding)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:40:36.048258Z","iopub.execute_input":"2025-03-31T14:40:36.048544Z","iopub.status.idle":"2025-03-31T14:40:36.111404Z","shell.execute_reply.started":"2025-03-31T14:40:36.048523Z","shell.execute_reply":"2025-03-31T14:40:36.110776Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"df_train['id'].unique(),df_test['id'].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:40:38.048880Z","iopub.execute_input":"2025-03-31T14:40:38.049232Z","iopub.status.idle":"2025-03-31T14:40:38.057518Z","shell.execute_reply.started":"2025-03-31T14:40:38.049205Z","shell.execute_reply":"2025-03-31T14:40:38.056693Z"}},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"(array([ 0,  7,  3, 13, 12,  4,  9,  1,  6, 17,  8, 16, 18, 11,  2, 14, 19,\n         5, 10, 15]),\n array([ 0,  2, 18]))"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"import os\nfrom shutil import copy\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:40:40.232008Z","iopub.execute_input":"2025-03-31T14:40:40.232335Z","iopub.status.idle":"2025-03-31T14:40:40.235824Z","shell.execute_reply.started":"2025-03-31T14:40:40.232310Z","shell.execute_reply":"2025-03-31T14:40:40.234953Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"cols = ['filename','id','center_x','center_y','w','h']\ngroup_obj_train=df_train[cols].groupby('filename')\ngroup_obj_test=df_test[cols].groupby('filename')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:40:42.126006Z","iopub.execute_input":"2025-03-31T14:40:42.126316Z","iopub.status.idle":"2025-03-31T14:40:42.137681Z","shell.execute_reply.started":"2025-03-31T14:40:42.126294Z","shell.execute_reply":"2025-03-31T14:40:42.136946Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"#save each image in train/test folder and respective labels in  .txt\ndef save_data(filename,folder_path,group_obj):\n    src = os.path.join('/kaggle/input/pascal-voc-2012-dataset/VOC2012_train_val/VOC2012_train_val/JPEGImages',filename)\n    dst = os.path.join(folder_path,filename)\n    copy(src,dst)\n\n    #save the labels\n    text_filename=os.path.join(folder_path,os.path.splitext(filename)[0]+'.txt') \n    group_obj.get_group(filename).set_index('filename').to_csv(text_filename,sep=' ',index=False,header=False)\n              ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:40:44.006784Z","iopub.execute_input":"2025-03-31T14:40:44.007059Z","iopub.status.idle":"2025-03-31T14:40:44.011713Z","shell.execute_reply.started":"2025-03-31T14:40:44.007039Z","shell.execute_reply":"2025-03-31T14:40:44.010762Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"filename_series= pd.Series(group_obj_train.groups.keys())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:40:46.003523Z","iopub.execute_input":"2025-03-31T14:40:46.003806Z","iopub.status.idle":"2025-03-31T14:40:46.316159Z","shell.execute_reply.started":"2025-03-31T14:40:46.003784Z","shell.execute_reply":"2025-03-31T14:40:46.312062Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"filename_series","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:40:49.173296Z","iopub.execute_input":"2025-03-31T14:40:49.173617Z","iopub.status.idle":"2025-03-31T14:40:49.179837Z","shell.execute_reply.started":"2025-03-31T14:40:49.173590Z","shell.execute_reply":"2025-03-31T14:40:49.179160Z"}},"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"0        2007_000027.jpg\n1        2007_000032.jpg\n2        2007_000033.jpg\n3        2007_000039.jpg\n4        2007_000042.jpg\n              ...       \n17120    2012_004326.jpg\n17121    2012_004328.jpg\n17122    2012_004329.jpg\n17123    2012_004330.jpg\n17124    2012_004331.jpg\nLength: 17125, dtype: object"},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"filename_series.apply(save_data,args=('/kaggle/working/yolov5/data_images/train',group_obj_train))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:40:52.830197Z","iopub.execute_input":"2025-03-31T14:40:52.830549Z","iopub.status.idle":"2025-03-31T14:43:59.739940Z","shell.execute_reply.started":"2025-03-31T14:40:52.830522Z","shell.execute_reply":"2025-03-31T14:43:59.739176Z"}},"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"0        None\n1        None\n2        None\n3        None\n4        None\n         ... \n17120    None\n17121    None\n17122    None\n17123    None\n17124    None\nLength: 17125, dtype: object"},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"filename_series_test= pd.Series(group_obj_test.groups.keys())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:44:35.308384Z","iopub.execute_input":"2025-03-31T14:44:35.308720Z","iopub.status.idle":"2025-03-31T14:44:35.376217Z","shell.execute_reply.started":"2025-03-31T14:44:35.308694Z","shell.execute_reply":"2025-03-31T14:44:35.375499Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"filename_series_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:44:37.459513Z","iopub.execute_input":"2025-03-31T14:44:37.459815Z","iopub.status.idle":"2025-03-31T14:44:37.466430Z","shell.execute_reply.started":"2025-03-31T14:44:37.459790Z","shell.execute_reply":"2025-03-31T14:44:37.465529Z"}},"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"0       2008_000200.jpg\n1       2008_000210.jpg\n2       2008_000216.jpg\n3       2008_000228.jpg\n4       2008_000263.jpg\n             ...       \n5133    2012_004322.jpg\n5134    2012_004323.jpg\n5135    2012_004324.jpg\n5136    2012_004325.jpg\n5137    2012_004327.jpg\nLength: 5138, dtype: object"},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"#save each image in train/test folder and respective labels in  .txt\ndef save_data(filename,folder_path,group_obj):\n    src = os.path.join('/kaggle/input/pascal-voc-2012-dataset/VOC2012_test/VOC2012_test/JPEGImages',filename)\n    dst = os.path.join(folder_path,filename)\n    copy(src,dst)\n\n    #save the labels\n    text_filename=os.path.join(folder_path,os.path.splitext(filename)[0]+'.txt') \n    group_obj.get_group(filename).set_index('filename').to_csv(text_filename,sep=' ',index=False,header=False)\n              ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:44:40.627295Z","iopub.execute_input":"2025-03-31T14:44:40.627614Z","iopub.status.idle":"2025-03-31T14:44:40.632111Z","shell.execute_reply.started":"2025-03-31T14:44:40.627585Z","shell.execute_reply":"2025-03-31T14:44:40.631220Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"filename_series_test.apply(save_data,args=('/kaggle/working/yolov5/data_images/test',group_obj_test))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:44:43.232980Z","iopub.execute_input":"2025-03-31T14:44:43.233326Z","iopub.status.idle":"2025-03-31T14:45:39.007341Z","shell.execute_reply.started":"2025-03-31T14:44:43.233297Z","shell.execute_reply":"2025-03-31T14:45:39.006618Z"}},"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"0       None\n1       None\n2       None\n3       None\n4       None\n        ... \n5133    None\n5134    None\n5135    None\n5136    None\n5137    None\nLength: 5138, dtype: object"},"metadata":{}}],"execution_count":47},{"cell_type":"code","source":"import os\nos.chdir(\"/kaggle/working/yolov5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:45:44.572677Z","iopub.execute_input":"2025-03-31T14:45:44.572970Z","iopub.status.idle":"2025-03-31T14:45:44.576733Z","shell.execute_reply.started":"2025-03-31T14:45:44.572948Z","shell.execute_reply":"2025-03-31T14:45:44.575892Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"# Define file name and content\nfilename = \"/kaggle/working/yolov5/data.yaml\"  # Save in /kaggle/working/\ncontent = \"\"\"\ntrain:  data_images/train\nval: data_images/test\nnc: 19\nnames: ['person',\n        'car',\n        'chair',\n        'bottle',\n        'pottedplant',\n        'bird',\n        'dog',\n        'sofa',\n        'bicycle',\n        'horse',\n        'boat',\n        'motorbike',\n        'cat',\n        'tvmonitor',\n        'cow',\n        'sheep',\n        'aeroplane',\n        'train',\n        'diningtable',\n        'bus']\n\n\"\"\"\n\n# Create and write to the file\nwith open(filename, \"w\") as file:\n    file.write(content)\n\nprint(f\"File '{filename}' created and saved successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:45:46.643287Z","iopub.execute_input":"2025-03-31T14:45:46.643593Z","iopub.status.idle":"2025-03-31T14:45:46.649233Z","shell.execute_reply.started":"2025-03-31T14:45:46.643570Z","shell.execute_reply":"2025-03-31T14:45:46.648173Z"}},"outputs":[{"name":"stdout","text":"File '/kaggle/working/yolov5/data.yaml' created and saved successfully!\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"!cat data.yaml","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:45:51.312754Z","iopub.execute_input":"2025-03-31T14:45:51.313033Z","iopub.status.idle":"2025-03-31T14:45:51.440063Z","shell.execute_reply.started":"2025-03-31T14:45:51.313012Z","shell.execute_reply":"2025-03-31T14:45:51.439281Z"}},"outputs":[{"name":"stdout","text":"\ntrain:  data_images/train\nval: data_images/test\nnc: 19\nnames: ['person',\n        'car',\n        'chair',\n        'bottle',\n        'pottedplant',\n        'bird',\n        'dog',\n        'sofa',\n        'bicycle',\n        'horse',\n        'boat',\n        'motorbike',\n        'cat',\n        'tvmonitor',\n        'cow',\n        'sheep',\n        'aeroplane',\n        'train',\n        'diningtable',\n        'bus']\n\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"import os\nos.chdir(\"/kaggle/working/yolov5\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:45:54.609203Z","iopub.execute_input":"2025-03-31T14:45:54.609509Z","iopub.status.idle":"2025-03-31T14:45:54.613490Z","shell.execute_reply.started":"2025-03-31T14:45:54.609486Z","shell.execute_reply":"2025-03-31T14:45:54.612614Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"!python3 train.py --data data.yaml --batch-size 8 --name Model --epochs 35\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T14:46:51.994502Z","iopub.execute_input":"2025-03-31T14:46:51.994835Z","iopub.status.idle":"2025-03-31T19:51:00.427022Z","shell.execute_reply.started":"2025-03-31T14:46:51.994810Z","shell.execute_reply":"2025-03-31T19:51:00.426013Z"}},"outputs":[{"name":"stdout","text":"Collecting ultralytics\n  Downloading ultralytics-8.3.99-py3-none-any.whl.metadata (37 kB)\nRequirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\nRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.5)\nRequirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\nRequirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\nRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\nRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\nRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\nRequirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\nRequirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\nRequirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\nRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.3)\nRequirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\nCollecting ultralytics-thop>=2.0.0 (from ultralytics)\n  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\nDownloading ultralytics-8.3.99-py3-none-any.whl (976 kB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m976.9/976.9 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\nInstalling collected packages: ultralytics-thop, ultralytics\nSuccessfully installed ultralytics-8.3.99 ultralytics-thop-2.0.14\nCreating new Ultralytics Settings v0.0.6 file  \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n\u001b[34m\u001b[1mwandb\u001b[0m: WARNING  wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n2025-03-31 14:47:12.073312: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-03-31 14:47:12.293223: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-03-31 14:47:12.352867: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=35, batch_size=8, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=Model, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 \n\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['thop>=0.1.1'] not found, attempting AutoUpdate...\nCollecting thop>=0.1.1\n  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from thop>=0.1.1) (2.5.1+cu121)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->thop>=0.1.1) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->thop>=0.1.1) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->thop>=0.1.1) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->thop>=0.1.1) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->thop>=0.1.1) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->thop>=0.1.1) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->thop>=0.1.1) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->thop>=0.1.1) (3.0.2)\nDownloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\nInstalling collected packages: thop\nSuccessfully installed thop-0.1.1.post2209072238\n\n\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success  3.4s, installed 1 package: ['thop>=0.1.1']\n\u001b[31m\u001b[1mrequirements:\u001b[0m  \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n\nYOLOv5  v7.0-411-gf4d8a84c Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15095MiB)\n\n\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5  runs in Comet\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\nDownloading https://github.com/ultralytics/assets/releases/download/v0.0.0/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n100%|| 755k/755k [00:00<00:00, 16.5MB/s]\nDownloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n100%|| 14.1M/14.1M [00:00<00:00, 147MB/s]\n\nOverriding model.yaml nc=80 with nc=20\n\n                 from  n    params  module                                  arguments                     \n  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n 24      [17, 20, 23]  1     67425  models.yolo.Detect                      [20, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\nModel summary: 214 layers, 7073569 parameters, 7073569 gradients, 16.1 GFLOPs\n\nTransferred 343/349 items from yolov5s.pt\n/kaggle/working/yolov5/models/common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with amp.autocast(autocast):\n/kaggle/working/yolov5/models/common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with amp.autocast(autocast):\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\nWARNING  DP not recommended, use torch.distributed.run for best DDP Multi-GPU results.\nSee Multi-GPU Tutorial at https://docs.ultralytics.com/yolov5/tutorials/multi_gpu_training to get started.\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/yolov5/data_images/train... 17125 images, 0 back\u001b[0m\n\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/yolov5/data_images/train.cache\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/yolov5/data_images/test... 5138 images, 0 backgrou\u001b[0m\n\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/yolov5/data_images/test.cache\n\n\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.97 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset \nPlotting labels to runs/train/Model/labels.jpg... \n/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/kaggle/working/yolov5/train.py:355: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler(enabled=amp)\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1mruns/train/Model\u001b[0m\nStarting training for 35 epochs...\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n  0%|          | 0/2141 [00:00<?, ?it/s]/kaggle/working/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(amp):\n       0/34     0.986G     0.1225    0.03708    0.08476         41        640:  /kaggle/working/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(amp):\n       0/34      1.03G     0.1222    0.03915    0.08477         44        640:  /kaggle/working/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(amp):\n       0/34      1.03G     0.0604    0.03592    0.04617         21        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       5138       7330      0.231      0.278      0.264      0.177\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       1/34      2.69G     0.0468    0.03304    0.02397         40        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       5138       7330      0.234      0.429      0.258      0.171\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       2/34      2.69G    0.04678    0.03499    0.02531         17        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       5138       7330      0.228      0.409      0.244      0.151\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       3/34      2.69G    0.04759     0.0368    0.02796         26        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       5138       7330      0.212      0.434      0.241      0.148\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       4/34      2.69G    0.04655    0.03654    0.02673         19        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       5138       7330      0.206      0.245      0.232      0.143\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       5/34      2.69G    0.04532    0.03607    0.02471         10        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       5138       7330      0.223      0.431      0.247      0.156\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       6/34      2.69G    0.04373    0.03609    0.02368         27        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       5138       7330      0.243      0.579      0.257      0.165\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       7/34      2.69G    0.04299    0.03527    0.02235         27        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       5138       7330      0.216      0.442      0.246      0.161\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       8/34      2.69G    0.04228    0.03501     0.0213         24        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       5138       7330      0.229      0.421      0.263      0.172\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       9/34      2.69G    0.04139    0.03449    0.02028         27        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       5138       7330      0.221      0.601      0.254      0.168\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      10/34      2.69G    0.04098    0.03465    0.01963         14        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       5138       7330      0.275      0.365      0.274      0.182\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      11/34      2.69G    0.04034    0.03467    0.01922         17        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       5138       7330      0.233      0.438      0.262      0.178\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      12/34      2.69G    0.03982    0.03399    0.01828         17        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       5138       7330      0.242      0.424      0.265      0.182\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      13/34      2.69G     0.0395     0.0339     0.0179         20        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       5138       7330      0.213      0.454      0.259      0.177\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      14/34      2.69G    0.03902    0.03342    0.01751         37        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       5138       7330      0.259        0.4       0.27      0.184\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      15/34      2.69G     0.0386    0.03343    0.01689         44        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       5138       7330       0.23      0.438      0.265      0.185\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      16/34      2.69G    0.03801    0.03333    0.01628         30        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       5138       7330      0.254      0.404      0.268      0.188\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      17/34      2.69G    0.03774     0.0332    0.01572         38        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       5138       7330       0.25      0.405      0.268      0.186\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      18/34      2.69G    0.03744    0.03279    0.01556         29        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       5138       7330      0.231      0.441      0.267      0.188\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      19/34      2.69G    0.03692    0.03264    0.01478         21        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       5138       7330      0.224      0.621      0.273      0.192\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      20/34      2.69G    0.03645    0.03223     0.0145         41        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       5138       7330      0.233      0.432      0.269       0.19\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      21/34      2.69G    0.03632    0.03214    0.01433         13        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       5138       7330      0.251      0.416      0.271      0.193\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      22/34      2.69G    0.03579    0.03203    0.01361         22        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       5138       7330      0.243      0.433      0.271      0.193\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      23/34      2.69G    0.03567    0.03172    0.01339         18        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       5138       7330      0.224      0.448      0.267      0.192\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      24/34      2.69G    0.03528    0.03188    0.01294         18        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       5138       7330      0.229       0.62      0.274      0.197\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      25/34      2.69G    0.03499    0.03136     0.0125         19        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       5138       7330      0.226       0.45      0.274      0.196\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      26/34      2.69G    0.03453    0.03111    0.01205         27        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       5138       7330      0.258      0.409      0.276      0.198\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      27/34      2.69G    0.03377    0.03095    0.01174         28        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       5138       7330      0.256      0.413      0.277        0.2\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      28/34      2.69G    0.03373    0.03054    0.01152         23        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       5138       7330      0.247      0.423      0.278      0.201\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      29/34      2.69G    0.03321     0.0304    0.01109         24        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       5138       7330      0.261      0.401      0.277        0.2\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      30/34      2.69G     0.0329    0.03007    0.01066         28        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       5138       7330      0.232      0.614      0.277      0.202\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      31/34      2.69G    0.03262    0.02978    0.01038         16        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       5138       7330      0.245      0.431      0.274        0.2\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      32/34      2.69G    0.03227    0.02955    0.01012         24        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       5138       7330      0.238      0.437      0.273        0.2\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      33/34      2.69G    0.03175    0.02953   0.009683         20        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       5138       7330      0.242      0.435      0.274      0.201\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      34/34      2.69G    0.03154    0.02932   0.009269         19        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       5138       7330      0.238      0.442      0.274      0.202\n\n35 epochs completed in 5.029 hours.\nOptimizer stripped from runs/train/Model/weights/last.pt, 14.4MB\nOptimizer stripped from runs/train/Model/weights/best.pt, 14.4MB\n\nValidating runs/train/Model/weights/best.pt...\nFusing layers... \nModel summary: 157 layers, 7064065 parameters, 0 gradients, 15.9 GFLOPs\n                 Class     Images  Instances          P          R      mAP50   \n                   all       5138       7330      0.238      0.442      0.274      0.202\n                person       5138       7326      0.694      0.825      0.806      0.599\n                 chair       5138          2          0          0   0.000242   0.000101\n           diningtable       5138          2     0.0192        0.5     0.0167    0.00782\nResults saved to \u001b[1mruns/train/Model\u001b[0m\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"!python export.py --weights runs/train/Model/weights/best.pt --include torchscript onnx","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T19:57:34.072577Z","iopub.execute_input":"2025-03-31T19:57:34.072937Z","iopub.status.idle":"2025-03-31T19:57:43.371762Z","shell.execute_reply.started":"2025-03-31T19:57:34.072910Z","shell.execute_reply":"2025-03-31T19:57:43.370641Z"}},"outputs":[{"name":"stdout","text":"\u001b[34m\u001b[1mexport: \u001b[0mdata=data/coco128.yaml, weights=['runs/train/Model/weights/best.pt'], imgsz=[640, 640], batch_size=1, device=cpu, half=False, inplace=False, keras=False, optimize=False, int8=False, per_tensor=False, dynamic=False, cache=, simplify=False, mlmodel=False, opset=17, verbose=False, workspace=4, nms=False, agnostic_nms=False, topk_per_class=100, topk_all=100, iou_thres=0.45, conf_thres=0.25, include=['torchscript', 'onnx']\nYOLOv5  v7.0-411-gf4d8a84c Python-3.10.12 torch-2.5.1+cu121 CPU\n\nFusing layers... \nModel summary: 157 layers, 7064065 parameters, 0 gradients, 15.9 GFLOPs\n\n\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from runs/train/Model/weights/best.pt with output shape (1, 25200, 25) (13.7 MB)\n\n\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.5.1+cu121...\n\u001b[34m\u001b[1mTorchScript:\u001b[0m export success  1.9s, saved as runs/train/Model/weights/best.torchscript (27.4 MB)\n\n\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0...\n\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.8s, saved as runs/train/Model/weights/best.onnx (27.4 MB)\n\nExport complete (3.3s)\nResults saved to \u001b[1m/kaggle/working/yolov5/runs/train/Model/weights\u001b[0m\nDetect:          python detect.py --weights runs/train/Model/weights/best.onnx \nValidate:        python val.py --weights runs/train/Model/weights/best.onnx \nPyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'runs/train/Model/weights/best.onnx')  \nVisualize:       https://netron.app\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"!zip -r workspace.zip /kaggle/working/yolov5/runs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T20:00:04.072324Z","iopub.execute_input":"2025-03-31T20:00:04.072622Z","iopub.status.idle":"2025-03-31T20:00:08.730218Z","shell.execute_reply.started":"2025-03-31T20:00:04.072599Z","shell.execute_reply":"2025-03-31T20:00:08.729169Z"}},"outputs":[{"name":"stdout","text":"  adding: kaggle/working/yolov5/runs/ (stored 0%)\n  adding: kaggle/working/yolov5/runs/train/ (stored 0%)\n  adding: kaggle/working/yolov5/runs/train/Model/ (stored 0%)\n  adding: kaggle/working/yolov5/runs/train/Model/labels.jpg (deflated 15%)\n  adding: kaggle/working/yolov5/runs/train/Model/val_batch2_labels.jpg (deflated 8%)\n  adding: kaggle/working/yolov5/runs/train/Model/confusion_matrix.png (deflated 20%)\n  adding: kaggle/working/yolov5/runs/train/Model/val_batch2_pred.jpg (deflated 8%)\n  adding: kaggle/working/yolov5/runs/train/Model/val_batch0_pred.jpg (deflated 8%)\n  adding: kaggle/working/yolov5/runs/train/Model/train_batch1.jpg (deflated 4%)\n  adding: kaggle/working/yolov5/runs/train/Model/labels_correlogram.jpg (deflated 33%)\n  adding: kaggle/working/yolov5/runs/train/Model/results.csv (deflated 82%)\n  adding: kaggle/working/yolov5/runs/train/Model/val_batch1_labels.jpg (deflated 7%)\n  adding: kaggle/working/yolov5/runs/train/Model/F1_curve.png (deflated 15%)\n  adding: kaggle/working/yolov5/runs/train/Model/val_batch0_labels.jpg (deflated 9%)\n  adding: kaggle/working/yolov5/runs/train/Model/train_batch2.jpg (deflated 4%)\n  adding: kaggle/working/yolov5/runs/train/Model/weights/ (stored 0%)\n  adding: kaggle/working/yolov5/runs/train/Model/weights/last.pt (deflated 8%)\n  adding: kaggle/working/yolov5/runs/train/Model/weights/best.torchscript (deflated 15%)\n  adding: kaggle/working/yolov5/runs/train/Model/weights/best.onnx (deflated 15%)\n  adding: kaggle/working/yolov5/runs/train/Model/weights/best.pt (deflated 8%)\n  adding: kaggle/working/yolov5/runs/train/Model/opt.yaml (deflated 50%)\n  adding: kaggle/working/yolov5/runs/train/Model/R_curve.png (deflated 13%)\n  adding: kaggle/working/yolov5/runs/train/Model/val_batch1_pred.jpg (deflated 6%)\n  adding: kaggle/working/yolov5/runs/train/Model/train_batch0.jpg (deflated 4%)\n  adding: kaggle/working/yolov5/runs/train/Model/PR_curve.png (deflated 13%)\n  adding: kaggle/working/yolov5/runs/train/Model/results.png (deflated 7%)\n  adding: kaggle/working/yolov5/runs/train/Model/hyp.yaml (deflated 45%)\n  adding: kaggle/working/yolov5/runs/train/Model/events.out.tfevents.1743432476.051dbc839118.94.0 (deflated 30%)\n  adding: kaggle/working/yolov5/runs/train/Model/P_curve.png (deflated 13%)\n","output_type":"stream"}],"execution_count":55}]}